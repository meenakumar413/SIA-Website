<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Agents: Learn the Fundamentals First | Skills & Innovation Academy</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>

  <!-- Slide 1 -->
  <section class="slide purple-bg">
    <img src="logo.png" alt="SIA Logo" class="logo">
    <h1>AI Agents: Learn the Fundamentals First</h1>
    <h3>Based on KodeKloud’s Tutorial</h3>
    <p class="notes">
      Welcome! Today we’ll explore why mastering the fundamentals is essential before diving into AI agent development.> 
    </p>
  </section>

  <!-- Slide 2 -->
  <section class="slide blue-bg">
    <h2>Start with the Basics</h2>
    <ul>
      <li>AI agents rely on foundational concepts</li>
      <li>Skipping fundamentals leads to confusion</li>
      <li>Learn before you build</li>
    </ul>
    <p class="notes">
      Many developers rush into building agents without understanding how LLMs work. This slide sets the stage for why that’s risky.
    </p>
  </section>

  <!-- Slide 3 -->
  <section class="slide purple-bg">
    <h2>Real-Time Language Models</h2>
    <ul>
      <li>LLMs generate responses using tokens</li>
      <li>Context windows define memory scope</li>
      <li>Prompt structure affects output</li>
    </ul>
    <p class="notes">
      LLMs process inputs as tokens. Understanding context windows helps you design better prompts and manage memory.
    </p>
  </section>

  <!-- Slide 4 -->
  <section class="slide blue-bg">
    <h2>Representing Language Numerically</h2>
    <ul>
      <li>Embeddings turn words into numbers</li>
      <li>Vectors enable semantic search</li>
      <li>Used in AI memory and retrieval</li>
    </ul>
    <p class="notes">
      Embeddings are the backbone of semantic understanding. They allow AI to “remember” and “search” intelligently.
    </p>
  </section>

  <!-- Slide 5 -->
  <section class="slide purple-bg">
    <h2>LangChain Overview</h2>
    <ul>
      <li>LangChain connects LLMs to tools</li>
      <li>Modular components for workflows</li>
      <li>Ideal for building agents</li>
    </ul>
    <p class="notes">
      LangChain is a powerful framework that lets you build agents by chaining together prompts, tools, and memory.
    </p>
  </section>

  <!-- Slide 6 -->
  <section class="slide blue-bg">
    <h2>Practice Labs – API Calls</h2>
    <ul>
      <li>Make your first API call</li>
      <li>Understand request/response flow</li>
      <li>Build confidence with real data</li>
    </ul>
    <p class="notes">
      KodeKloud walks through making an OpenAI API call. This is your first step toward building functional agents.
    </p>
  </section>

  <!-- Slide 7 -->
  <section class="slide purple-bg">
    <h2>Prompt Engineering</h2>
    <ul>
      <li>Use zero-shot and few-shot prompts</li>
      <li>Chain-of-thought improves reasoning</li>
      <li>Test and iterate for clarity</li>
    </ul>
    <p class="notes">
      Prompt engineering is an art. Learn how to guide the model’s thinking with structured inputs.
    </p>
  </section>

  <!-- Slide 8 -->
  <section class="slide blue-bg">
    <h2>Vector Databases</h2>
    <ul>
      <li>Tools like Chro
